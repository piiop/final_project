{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "import io\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the preprocessed data\n",
    "imgs = pd.read_csv(\"training_imageset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8864 entries, 0 to 8863\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Style      8864 non-null   object\n",
      " 1   file_path  8864 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 138.6+ KB\n"
     ]
    }
   ],
   "source": [
    "imgs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the image files to floating point numpy arrays and normalize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 1/9\n",
      "Processed batch 2/9\n",
      "Processed batch 3/9\n",
      "Processed batch 4/9\n"
     ]
    }
   ],
   "source": [
    "# Convert to floating point and normalize\n",
    "def load_and_normalize_image(file_path):\n",
    "    \"\"\"\n",
    "    Load image from file_path, convert to float32 array and normalize to [0, 1] range\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the image file\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Normalized image array of shape (height, width, 3) in float32\n",
    "    \"\"\"\n",
    "    # Load image\n",
    "    img = Image.open(file_path)\n",
    "    \n",
    "    # Convert to RGB if not already\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    \n",
    "    # Convert to numpy array and change type to float32\n",
    "    img_array = np.array(img, dtype=np.float32)\n",
    "    \n",
    "    # Normalize to [0, 1] range\n",
    "    img_array = img_array / 255.0\n",
    "    \n",
    "    return img_array\n",
    "\n",
    "def load_images_in_batches(dataframe, batch_size=1000):\n",
    "    \"\"\"Load images in batches to prevent memory overload\"\"\"\n",
    "    all_arrays = []\n",
    "    \n",
    "    for i in range(0, len(dataframe), batch_size):\n",
    "        batch = dataframe.iloc[i:i+batch_size]\n",
    "        batch_arrays = batch['file_path'].apply(load_and_normalize_image)\n",
    "        all_arrays.extend(batch_arrays.values)\n",
    "        print(f\"Processed batch {i//batch_size + 1}/{(len(dataframe)//batch_size) + 1}\")\n",
    "        \n",
    "    return np.array(all_arrays)\n",
    "\n",
    "# Load images in batches\n",
    "image_arrays = load_images_in_batches(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "\n",
    "y = imgs['Style']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Style order:\n",
      "0: Abstract Expressionism\n",
      "1: Conceptual Art\n",
      "2: Early Renaissance\n",
      "3: Expressionism\n",
      "4: Baroque\n",
      "5: Cubism\n",
      "6: Contemporary Realism\n",
      "7: Art Informel\n",
      "8: Contemporary\n",
      "9: Realism\n",
      "10: Neo-romantic\n",
      "11: Post-impressionism\n",
      "12: Modern Art\n",
      "13: Modernism\n",
      "14: Surrealism\n",
      "15: Symbolism\n",
      "16: Rococo\n",
      "17: Northern Renaissance\n",
      "18: Pop Art\n",
      "19: Mannerism\n",
      "20: Late Renaissance\n",
      "21: Ukiyo-e\n",
      "22: High Renaissance\n",
      "23: Fauvism\n"
     ]
    }
   ],
   "source": [
    "unique_styles = imgs['Style'].unique()\n",
    "print(\"Style order:\")\n",
    "for i, style in enumerate(unique_styles):\n",
    "    print(f\"{i}: {style}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training dataset into training and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_cat shape: (7091, 24)\n",
      "y_test_cat shape: (1773, 24)\n"
     ]
    }
   ],
   "source": [
    "# First convert strings to numbers\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Then one-hot using tensorflows method\n",
    "y_train_cat = to_categorical(y_train_encoded)\n",
    "y_test_cat = to_categorical(y_test_encoded)\n",
    "\n",
    "print(\"y_train_cat shape:\", y_train_cat.shape)\n",
    "print(\"y_test_cat shape:\", y_test_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (7091, 256, 256, 3)\n",
      "X_test shape: (1773, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# Convert list/series of arrays into a single 4D tensor\n",
    "X_train = np.stack(X_train.values)\n",
    "X_test = np.stack(X_test.values)\n",
    "\n",
    "# Check shapes\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a CNN model\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(60, 64, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(24, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the testing data\n",
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
