{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_utils.py\n",
    "\n",
    "import os\n",
    "from typing import Tuple, Dict, List\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "class ArtDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading art images.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str,\n",
    "        metadata_file: str,\n",
    "        transform=None,\n",
    "        mode: str = 'train'\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir (str): Directory with all the images\n",
    "            metadata_file (str): Path to the metadata CSV file\n",
    "            transform: Optional transform to be applied on images\n",
    "            mode (str): 'train', 'val', or 'test'\n",
    "        \"\"\"\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        \n",
    "        # Read metadata\n",
    "        self.metadata = pd.read_csv(metadata_file)\n",
    "        \n",
    "        # Create class mapping\n",
    "        self.class_to_idx = {\n",
    "            cls: idx for idx, cls in enumerate(self.metadata['style'].unique())\n",
    "        }\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.metadata)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        # Get image path and label\n",
    "        row = self.metadata.iloc[idx]\n",
    "        img_path = self.data_dir / row['filename']\n",
    "        label = self.class_to_idx[row['style']]\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "def get_data_transforms(img_size: int = 224) -> Dict[str, transforms.Compose]:\n",
    "    \"\"\"\n",
    "    Get train and validation transforms.\n",
    "    \n",
    "    Args:\n",
    "        img_size (int): Size to resize images to\n",
    "    \n",
    "    Returns:\n",
    "        Dict containing train and validation transforms\n",
    "    \"\"\"\n",
    "    train_transform = A.Compose([\n",
    "        A.RandomCrop(height=img_size, width=img_size),\n",
    "        A.Rotate(limit=10),\n",
    "        A.RandomBrightnessContrast(\n",
    "            brightness_limit=0.1,\n",
    "            contrast_limit=0.1\n",
    "        ),\n",
    "        A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    \n",
    "    val_transform = A.Compose([\n",
    "        A.Resize(img_size, img_size),\n",
    "        A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    \n",
    "    return {'train': train_transform, 'val': val_transform}\n",
    "\n",
    "def create_data_loaders(\n",
    "    data_dir: str,\n",
    "    metadata_file: str,\n",
    "    batch_size: int = 32,\n",
    "    num_workers: int = 4,\n",
    "    img_size: int = 224\n",
    ") -> Dict[str, DataLoader]:\n",
    "    \"\"\"\n",
    "    Create train and validation data loaders.\n",
    "    \n",
    "    Args:\n",
    "        data_dir (str): Directory containing images\n",
    "        metadata_file (str): Path to metadata CSV\n",
    "        batch_size (int): Batch size for training\n",
    "        num_workers (int): Number of workers for data loading\n",
    "        img_size (int): Size to resize images to\n",
    "    \n",
    "    Returns:\n",
    "        Dict containing train and validation DataLoaders\n",
    "    \"\"\"\n",
    "    transforms = get_data_transforms(img_size)\n",
    "    \n",
    "    datasets = {\n",
    "        mode: ArtDataset(\n",
    "            data_dir=data_dir,\n",
    "            metadata_file=metadata_file,\n",
    "            transform=transforms[mode],\n",
    "            mode=mode\n",
    "        )\n",
    "        for mode in ['train', 'val']\n",
    "    }\n",
    "    \n",
    "    dataloaders = {\n",
    "        mode: DataLoader(\n",
    "            datasets[mode],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=(mode == 'train'),\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        for mode in ['train', 'val']\n",
    "    }\n",
    "    \n",
    "    return dataloaders\n",
    "\n",
    "def get_class_weights(metadata_file: str) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculate class weights for imbalanced datasets.\n",
    "    \n",
    "    Args:\n",
    "        metadata_file (str): Path to metadata CSV\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Class weights for weighted loss function\n",
    "    \"\"\"\n",
    "    metadata = pd.read_csv(metadata_file)\n",
    "    class_counts = metadata['style'].value_counts()\n",
    "    total = len(metadata)\n",
    "    \n",
    "    weights = torch.tensor([\n",
    "        total / (len(class_counts) * count)\n",
    "        for count in class_counts\n",
    "    ])\n",
    "    \n",
    "    return weights\n",
    "\n",
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    data_dir = \"path/to/images\"\n",
    "    metadata_file = \"path/to/metadata.csv\"\n",
    "    \n",
    "    dataloaders = create_data_loaders(\n",
    "        data_dir=data_dir,\n",
    "        metadata_file=metadata_file,\n",
    "        batch_size=32\n",
    "    )\n",
    "    \n",
    "    # Example iteration\n",
    "    for images, labels in dataloaders['train']:\n",
    "        print(f\"Batch shape: {images.shape}\")\n",
    "        print(f\"Labels shape: {labels.shape}\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
