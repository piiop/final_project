{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\16148\\anaconda3\\envs\\dev\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\16148\\anaconda3\\envs\\dev\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from typing import Tuple\n",
    "import io\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Import the ArtAnalyzer class\n",
    "from artclass_class import ArtAnalyzer\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "\n",
    "def init_analyzer():\n",
    "    style_labels = [\n",
    "    \"naive_art\",\n",
    "    \"baroque\",\n",
    "    \"rococo\",\n",
    "    \"romanticism\",\n",
    "    \"art_deco\",\n",
    "    \"american_realism\",\n",
    "    \"art_nouveau\",\n",
    "    \"expressionism\",\n",
    "    \"modernism\",\n",
    "    \"post_impressionism\",\n",
    "    \"high_renaissance\",\n",
    "    \"cubism\",\n",
    "    \"abstract_expressionism\",\n",
    "    \"art_informel\",\n",
    "    \"mannerism\",\n",
    "    \"northern_renaissance\",\n",
    "    \"surrealism\",\n",
    "    \"symbolism\",\n",
    "    \"early_renaissance\",\n",
    "    \"neo_romantic\",\n",
    "    \"ukiyo_e\",\n",
    "    \"impressionism\",\n",
    "    \"pop_art\",\n",
    "    \"fauvism\",\n",
    "    \"neoclassicism\",\n",
    "    \"minimalism\"\n",
    "    ]\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(style_labels)\n",
    "    style_labels = label_encoder.classes_\n",
    "\n",
    "    try:\n",
    "        return ArtAnalyzer(\n",
    "            cnn_model_path=\"art_classifier_curated.keras\",\n",
    "            style_labels=style_labels\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Initialize analyzer globally\n",
    "analyzer = init_analyzer()\n",
    "\n",
    "def preprocess_image(image):\n",
    "    try:\n",
    "        if isinstance(image, str):\n",
    "            img = Image.open(image)\n",
    "        elif isinstance(image, np.ndarray):\n",
    "            # BGR to RGB if from numpy/Gradio\n",
    "            image = image[..., ::-1]\n",
    "            img = Image.fromarray(image)\n",
    "        else:\n",
    "            return None, \"Unsupported image format\"\n",
    "            \n",
    "        # Always convert to RGB\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "            \n",
    "        # Resize first\n",
    "        target_size = 256\n",
    "        w, h = img.size\n",
    "        ratio = min(target_size / w, target_size / h)\n",
    "        new_w = int(w * ratio)\n",
    "        new_h = int(h * ratio)\n",
    "        resized = img.resize((new_w, new_h), Image.LANCZOS)\n",
    "        \n",
    "        # Calculate mean color from resized image\n",
    "        resized_array = np.array(resized)\n",
    "        mean_color = tuple(map(int, np.mean(resized_array, axis=(0, 1))))\n",
    "        \n",
    "        # Create padded image\n",
    "        new_image = Image.new('RGB', (target_size, target_size), mean_color)\n",
    "        \n",
    "        # Calculate padding\n",
    "        x_offset = (target_size - new_w) // 2\n",
    "        y_offset = (target_size - new_h) // 2\n",
    "        \n",
    "        # Paste the resized image\n",
    "        new_image.paste(resized, (x_offset, y_offset))\n",
    "        \n",
    "        # Convert to numpy and normalize\n",
    "        final_array = np.array(new_image, dtype=np.float32) / 255.0\n",
    "        \n",
    "        return final_array, None\n",
    "            \n",
    "    except Exception as e:\n",
    "        return None, f\"Error processing image: {str(e)}\"\n",
    "\n",
    "def process_and_analyze(image: np.ndarray, question: str) -> Tuple[str, str]:\n",
    "    try:\n",
    "        if image is None:\n",
    "            return \"Error: No image provided\", \"Please upload an image\"\n",
    "            \n",
    "        # Preprocess image\n",
    "        img_array, error = preprocess_image(image)\n",
    "        if error:\n",
    "            return f\"Error: {error}\", \"Unable to process image\"\n",
    "            \n",
    "        # Get predictions\n",
    "        predictions = analyzer.analyze_image(img_array)\n",
    "        \n",
    "        # Format style predictions with proper newlines and spacing\n",
    "        style_output = \"Top Predicted Styles:\\n\"\n",
    "        sorted_predictions = sorted(predictions.items(), key=lambda x: x[1], reverse=True)\n",
    "        for style, conf in sorted_predictions[:3]:  # Show top 3 for better context\n",
    "            style_output += f\"{style}: {conf*100:.2f}%\\n\"\n",
    "        \n",
    "        response = analyzer.answer_question(question, predictions)\n",
    "        if \"Question:\" in response:\n",
    "            response = response.split(\"Answer:\", 1)[-1].strip()\n",
    "        \n",
    "        return style_output, response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in process_and_analyze: {str(e)}\")\n",
    "        return f\"Error: {str(e)}\", \"An unexpected error occurred\"\n",
    "\n",
    "# Then, the Gradio interface:\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Art Style Analyzer\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        image_input = gr.Image(\n",
    "            type=\"numpy\",\n",
    "            label=\"Upload artwork (supported formats: jpg, png, webp)\"\n",
    "        )\n",
    "        question_input = gr.Textbox(\n",
    "            label=\"Ask a question about the artwork\",\n",
    "            placeholder=\"What techniques are used in this style?\"\n",
    "        )\n",
    "    \n",
    "    with gr.Row():\n",
    "        style_output = gr.Textbox(label=\"Style Predictions\")\n",
    "        answer_output = gr.Textbox(label=\"Answer\")\n",
    "    \n",
    "    analyze_btn = gr.Button(\"Analyze Artwork\")\n",
    "    \n",
    "    analyze_btn.click(\n",
    "        fn=process_and_analyze,\n",
    "        inputs=[image_input, question_input],\n",
    "        outputs=[style_output, answer_output]\n",
    "    )\n",
    "\n",
    "# Launch the interface\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
